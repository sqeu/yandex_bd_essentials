{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division, print_function, unicode_literals # For the compatibility with Python 2\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark_session = SparkSession.builder\\\n",
    "                            .enableHiveSupport()\\\n",
    "                            .appName(\"sparksql\")\\\n",
    "                            .master(\"local[4]\")\\\n",
    "                            .getOrCreate()\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = spark_session.sparkContext\n",
    "df = spark_session.read.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferschema\", \"true\")\\\n",
    "        .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "        .load(\"/data/covertype2/train.csv\")\\\n",
    "        .repartition(60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "cat_cols=['Soil_Type','Wild_Type']\n",
    "cat_cols_index={'Soil_Type':'Soil_Index','Wild_Type':'Wild_Index'}\n",
    "cat_cols_encoder={'Soil_Index':'SoilEncoder','Wild_Index':'WildEncoder'}\n",
    "\n",
    "stringIndexer = StringIndexer(inputCol = \"Soil_Type\", outputCol = \"Soil_Index\")\n",
    "model1 = stringIndexer.fit(df)\n",
    "indexedDF = model1.transform(df)\n",
    "\n",
    "stringIndexer2 = StringIndexer(inputCol = \"Wild_Type\", outputCol = \"Wild_Index\")\n",
    "model2 = stringIndexer2.fit(indexedDF)\n",
    "indexedDF2 = model2.transform(indexedDF)\n",
    "\n",
    "from pyspark.ml.feature import OneHotEncoder\n",
    "encoder = OneHotEncoder(inputCol = \"Soil_Index\", outputCol = \"SoilEncoder\")\n",
    "encoder.setDropLast(False)\n",
    "encodedDF = encoder.transform(indexedDF2)\n",
    "\n",
    "encoder2 = OneHotEncoder(inputCol = \"Wild_Index\", outputCol = \"WildEncoder\")\n",
    "encoder2.setDropLast(False)\n",
    "encodedDF2 = encoder2.transform(encodedDF)\n",
    "\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "vector_assembler = VectorAssembler(inputCols=['SoilEncoder','WildEncoder','Elevation','Aspect','Slope','Horizontal_Distance_To_Hydrology','Vertical_Distance_To_Hydrology','Horizontal_Distance_To_Roadways','Hillshade_9am','Hillshade_Noon','Hillshade_3pm','Horizontal_Distance_To_Fire_Points'], outputCol='features')\n",
    "finalDF = vector_assembler.transform(encodedDF2)\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.classification import RandomForestClassifier, RandomForestClassificationModel\n",
    "rf = RandomForestClassifier(labelCol='Target',featuresCol= \"features\",numTrees=100, maxDepth=9)\n",
    "\n",
    "trainingData, testData = finalDF.randomSplit([0.8, 0.2], seed = 123)\n",
    "\n",
    "model = rf.fit(trainingData)\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTest = spark_session.read.format(\"com.databricks.spark.csv\")\\\n",
    "        .option(\"header\", \"true\")\\\n",
    "        .option(\"inferschema\", \"true\")\\\n",
    "        .option(\"mode\", \"DROPMALFORMED\")\\\n",
    "        .load(\"/data/covertype2\")\\\n",
    "        .repartition(60)prediction = model.transform(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = stringIndexer.fit(dfTest)\n",
    "indexedDFTest = model1.transform(dfTest)\n",
    "\n",
    "model2 = stringIndexer2.fit(indexedDFTest)\n",
    "indexedDF2Test= model2.transform(indexedDFTest)\n",
    "\n",
    "encodedDFTest = encoder.transform(indexedDF2Test)\n",
    "\n",
    "encodedDF2Test = encoder2.transform(encodedDFTest)\n",
    "finalDFTest = vector_assembler.transform(encodedDF2Test)\n",
    "predictions = model.transform(finalDFTest)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol = \"Target\", predictionCol = \"prediction\", metricName = \"accuracy\")\n",
    "accuracy = evaluator.evaluate(predictions)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
