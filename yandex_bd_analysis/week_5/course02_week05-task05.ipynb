{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to\n",
      "      ____              __\n",
      "     / __/__  ___ _____/ /__\n",
      "    _\\ \\/ _ \\/ _ `/ __/  '_/\n",
      "   /__ / .__/\\_,_/_/ /_/\\_\\   version 2.1.1\n",
      "      /_/\n",
      "\n",
      "Using Python version 2.7.12 (default, Nov 19 2016 06:48:10)\n",
      "SparkSession available as 'spark'.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "execfile(os.path.join(os.environ[\"SPARK_HOME\"], 'python/pyspark/shell.py'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "sparkSession = SparkSession.builder.enableHiveSupport().master(\"local [2]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sparkSession.read.parquet(\"/data/sample264\")\n",
    "meta = sparkSession.read.parquet(\"/data/meta\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalization could be done by next function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(df, key1, key2, field, n): \n",
    "    \n",
    "    window = Window.partitionBy(key1).orderBy(col(field).desc())\n",
    "        \n",
    "    topsDF = df.withColumn(\"row_number\", row_number().over(window)) \\\n",
    "        .filter(col(\"row_number\") <= n) \\\n",
    "        .drop(col(\"row_number\")) \n",
    "        \n",
    "    tmpDF = topsDF.groupBy(col(key1)).agg(col(key1), sum(col(field)).alias(\"sum_\" + field))\n",
    "   \n",
    "    normalizedDF = topsDF.join(tmpDF, key1, \"inner\") \\\n",
    "        .withColumn(\"norm_\" + field, col(field) / col(\"sum_\" + field)) \\\n",
    "        .cache()\n",
    "\n",
    "    return normalizedDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Window\n",
    "from pyspark.sql.functions import row_number, sum,desc,when,col, rank,lit\n",
    "\n",
    "user = data.where(\"userId=776748\")\\\n",
    "    .select(\"artistId\",\"trackId\").distinct()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_a = user.alias(\"a\").withColumnRenamed(\"artistId\",\"id_meta\").select(\"id_meta\")\n",
    "user_b = user.alias(\"b\").withColumnRenamed(\"trackId\",\"id_meta\").select(\"id_meta\")\n",
    "\n",
    "user_u=user_a.union(user_b).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "artistsList = user_u.join(meta,user_u[\"id_meta\"]==meta[\"Id\"])\\\n",
    "                    .select(\"artist\",\"name\")\\\n",
    "                    .orderBy(\"artist\",\"name\")\\\n",
    "                    .take(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artist: 3 Doors Down Artist: 3 Doors Down\n",
      "Artist: 3 Doors Down Kryptonite\n",
      "Artist: 311 Artist: 311\n",
      "Artist: 311 Beautiful disaster\n",
      "Artist: Blur Artist: Blur\n",
      "Artist: Blur Girls and Boys\n",
      "Artist: Clawfinger Artist: Clawfinger\n",
      "Artist: Clawfinger Nothing Going On\n",
      "Artist: Disturbed Artist: Disturbed\n",
      "Artist: Disturbed The Vengeful One\n",
      "Artist: Gotthard Artist: Gotthard\n",
      "Artist: Gotthard Eagle\n",
      "Artist: Green Day 21 Guns\n",
      "Artist: Green Day Artist: Green Day\n",
      "Artist: Green Day Kill The DJ\n",
      "Artist: Iggy Pop Artist: Iggy Pop\n",
      "Artist: Iggy Pop Sunday\n",
      "Artist: Korn Artist: Korn\n",
      "Artist: Korn Here To Stay\n",
      "Artist: Linkin Park Artist: Linkin Park\n",
      "Artist: Linkin Park In The End\n",
      "Artist: Linkin Park Numb\n",
      "Artist: Lordi Artist: Lordi\n",
      "Artist: Lordi Hard Rock Hallelujah\n",
      "Artist: Nickelback Artist: Nickelback\n",
      "Artist: Nickelback She Keeps Me Up\n",
      "Artist: Nomy Artist: Nomy\n",
      "Artist: Nomy Cocaine\n",
      "Artist: Papa Roach Artist: Papa Roach\n",
      "Artist: Papa Roach Getting Away With Murder\n",
      "Artist: Rise Against Artist: Rise Against\n",
      "Artist: Rise Against Prayer Of The Refugee\n",
      "Artist: Serj Tankian Artist: Serj Tankian\n",
      "Artist: Serj Tankian Sky is Over\n",
      "Artist: Slipknot Artist: Slipknot\n",
      "Artist: Slipknot Wait And Bleed\n",
      "Artist: The Offspring Artist: The Offspring\n",
      "Artist: The Offspring Come Out and Play\n",
      "Artist: Thousand Foot Krutch Artist: Thousand Foot Krutch\n",
      "Artist: Thousand Foot Krutch Take It Out On Me\n"
     ]
    }
   ],
   "source": [
    "for val in artistsList:\n",
    "    print \"%s %s\" % val"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
