{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZfiL39OTJ5sR"
   },
   "source": [
    "# Hive assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting assg2_result.hql\n"
     ]
    }
   ],
   "source": [
    "%%writefile assg2_result.hql\n",
    "-- Your code here\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-contrib.jar;\n",
    "ADD JAR /opt/cloudera/parcels/CDH/lib/hive/lib/hive-serde.jar;\n",
    "\n",
    "use stackoverflow_;\n",
    "\n",
    "select \n",
    "concat_ws(\"\\t\",exploded_tags,CAST(rank2016 as string),CAST(rank2009 AS STRING),\n",
    "          CAST(pop2016 AS STRING),CAST(pop2009 AS STRING))\n",
    "from\n",
    "    (select t2016.exploded_tags as exploded_tags\n",
    "     ,t2016.rank as rank2016\n",
    "     ,t2009.rank as rank2009\n",
    "     ,t2016.popularity as pop2016\n",
    "     ,t2009.popularity as pop2009\n",
    "    from\n",
    "        (select exploded_tags, count(*) as popularity\n",
    "        ,rank() over (order by count(*) DESC) as rank\n",
    "        from posts\n",
    "        lateral view outer explode(tags) tag_tab as exploded_tags\n",
    "        where year='2016' and post_type_id=1 and tags is not null\n",
    "        group by exploded_tags) t2016\n",
    "    JOIN\n",
    "        (select exploded_tags, count(*) as popularity\n",
    "        ,rank() over (order by count(*) DESC) as rank\n",
    "        from posts\n",
    "        lateral view outer explode(tags) tag_tab as exploded_tags\n",
    "        where year='2009' and post_type_id=1 and tags is not null\n",
    "        group by exploded_tags) t2009\n",
    "    on t2016.exploded_tags=t2009.exploded_tags\n",
    "    order by rank2016 asc\n",
    "    limit 10) t\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Logging initialized using configuration in jar:file:/usr/local/apache-hive-1.1.0-bin/lib/hive-common-1.1.0.jar!/hive-log4j.properties\n",
      "Query ID = jovyan_20190930025858_ca77b7b3-3d91-4b78-88ed-505cf17f7322\n",
      "Total jobs = 8\n",
      "Launching Job 1 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1569802179163_0038, Tracking URL = http://d37663a6e069:8088/proxy/application_1569802179163_0038/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1569802179163_0038\n",
      "Hadoop job information for Stage-1: number of mappers: 1; number of reducers: 1\n",
      "2019-09-30 02:58:44,785 Stage-1 map = 0%,  reduce = 0%\n",
      "2019-09-30 02:58:57,272 Stage-1 map = 100%,  reduce = 0%, Cumulative CPU 2.78 sec\n",
      "2019-09-30 02:59:07,372 Stage-1 map = 100%,  reduce = 100%, Cumulative CPU 5.05 sec\n",
      "MapReduce Total cumulative CPU time: 5 seconds 50 msec\n",
      "Ended Job = job_1569802179163_0038\n",
      "Launching Job 2 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1569802179163_0039, Tracking URL = http://d37663a6e069:8088/proxy/application_1569802179163_0039/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1569802179163_0039\n",
      "Hadoop job information for Stage-5: number of mappers: 1; number of reducers: 1\n",
      "2019-09-30 02:59:24,476 Stage-5 map = 0%,  reduce = 0%\n",
      "2019-09-30 02:59:34,367 Stage-5 map = 100%,  reduce = 0%, Cumulative CPU 2.21 sec\n",
      "2019-09-30 02:59:45,109 Stage-5 map = 100%,  reduce = 100%, Cumulative CPU 4.31 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 310 msec\n",
      "Ended Job = job_1569802179163_0039\n",
      "Launching Job 3 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1569802179163_0040, Tracking URL = http://d37663a6e069:8088/proxy/application_1569802179163_0040/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1569802179163_0040\n",
      "Hadoop job information for Stage-2: number of mappers: 1; number of reducers: 1\n",
      "2019-09-30 03:00:02,190 Stage-2 map = 0%,  reduce = 0%\n",
      "2019-09-30 03:00:10,832 Stage-2 map = 100%,  reduce = 0%, Cumulative CPU 1.62 sec\n",
      "2019-09-30 03:00:21,585 Stage-2 map = 100%,  reduce = 100%, Cumulative CPU 4.27 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 270 msec\n",
      "Ended Job = job_1569802179163_0040\n",
      "Launching Job 4 out of 8\n",
      "Number of reduce tasks not specified. Estimated from input data size: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1569802179163_0041, Tracking URL = http://d37663a6e069:8088/proxy/application_1569802179163_0041/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1569802179163_0041\n",
      "Hadoop job information for Stage-6: number of mappers: 1; number of reducers: 1\n",
      "2019-09-30 03:00:38,511 Stage-6 map = 0%,  reduce = 0%\n",
      "2019-09-30 03:00:48,395 Stage-6 map = 100%,  reduce = 0%, Cumulative CPU 1.67 sec\n",
      "2019-09-30 03:01:00,145 Stage-6 map = 100%,  reduce = 100%, Cumulative CPU 4.13 sec\n",
      "MapReduce Total cumulative CPU time: 4 seconds 130 msec\n",
      "Ended Job = job_1569802179163_0041\n",
      "Stage-10 is selected by condition resolver.\n",
      "Stage-11 is filtered out by condition resolver.\n",
      "Stage-3 is filtered out by condition resolver.\n",
      "Execution log at: /tmp/jovyan/jovyan_20190930025858_ca77b7b3-3d91-4b78-88ed-505cf17f7322.log\n",
      "2019-09-30 03:01:07\tStarting to launch local task to process map join;\tmaximum memory = 518979584\n",
      "2019-09-30 03:01:09\tDump the side-table for tag: 1 with group count: 2369 into file: file:/tmp/jovyan/b47292a1-11f1-4a0f-9fc2-76d791d42cd5/hive_2019-09-30_02-58-25_907_2604042602726384777-1/-local-10008/HashTable-Stage-7/MapJoin-mapfile01--.hashtable\n",
      "2019-09-30 03:01:09\tUploaded 1 File to: file:/tmp/jovyan/b47292a1-11f1-4a0f-9fc2-76d791d42cd5/hive_2019-09-30_02-58-25_907_2604042602726384777-1/-local-10008/HashTable-Stage-7/MapJoin-mapfile01--.hashtable (76823 bytes)\n",
      "2019-09-30 03:01:09\tEnd of local task; Time Taken: 1.434 sec.\n",
      "Execution completed successfully\n",
      "MapredLocal task succeeded\n",
      "Launching Job 6 out of 8\n",
      "Number of reduce tasks is set to 0 since there's no reduce operator\n",
      "Starting Job = job_1569802179163_0042, Tracking URL = http://d37663a6e069:8088/proxy/application_1569802179163_0042/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1569802179163_0042\n",
      "Hadoop job information for Stage-7: number of mappers: 1; number of reducers: 0\n",
      "2019-09-30 03:01:21,401 Stage-7 map = 0%,  reduce = 0%\n",
      "2019-09-30 03:01:30,006 Stage-7 map = 100%,  reduce = 0%, Cumulative CPU 1.72 sec\n",
      "MapReduce Total cumulative CPU time: 1 seconds 720 msec\n",
      "Ended Job = job_1569802179163_0042\n",
      "Launching Job 7 out of 8\n",
      "Number of reduce tasks determined at compile time: 1\n",
      "In order to change the average load for a reducer (in bytes):\n",
      "  set hive.exec.reducers.bytes.per.reducer=<number>\n",
      "In order to limit the maximum number of reducers:\n",
      "  set hive.exec.reducers.max=<number>\n",
      "In order to set a constant number of reducers:\n",
      "  set mapreduce.job.reduces=<number>\n",
      "Starting Job = job_1569802179163_0043, Tracking URL = http://d37663a6e069:8088/proxy/application_1569802179163_0043/\n",
      "Kill Command = /opt/hadoop/bin/hadoop job  -kill job_1569802179163_0043\n",
      "Hadoop job information for Stage-4: number of mappers: 1; number of reducers: 1\n",
      "2019-09-30 03:01:47,109 Stage-4 map = 0%,  reduce = 0%\n",
      "2019-09-30 03:01:56,780 Stage-4 map = 100%,  reduce = 0%, Cumulative CPU 1.7 sec\n",
      "2019-09-30 03:02:06,379 Stage-4 map = 100%,  reduce = 100%, Cumulative CPU 3.75 sec\n",
      "MapReduce Total cumulative CPU time: 3 seconds 750 msec\n",
      "Ended Job = job_1569802179163_0043\n",
      "MapReduce Jobs Launched: \n",
      "Stage-Stage-1: Map: 1  Reduce: 1   Cumulative CPU: 5.05 sec   HDFS Read: 834924 HDFS Write: 283234 SUCCESS\n",
      "Stage-Stage-5: Map: 1  Reduce: 1   Cumulative CPU: 4.31 sec   HDFS Read: 145024 HDFS Write: 67863 SUCCESS\n",
      "Stage-Stage-2: Map: 1  Reduce: 1   Cumulative CPU: 4.27 sec   HDFS Read: 289426 HDFS Write: 311766 SUCCESS\n",
      "Stage-Stage-6: Map: 1  Reduce: 1   Cumulative CPU: 4.13 sec   HDFS Read: 74055 HDFS Write: 74637 SUCCESS\n",
      "Stage-Stage-7: Map: 1   Cumulative CPU: 1.72 sec   HDFS Read: 316231 HDFS Write: 55844 SUCCESS\n",
      "Stage-Stage-4: Map: 1  Reduce: 1   Cumulative CPU: 3.75 sec   HDFS Read: 61405 HDFS Write: 188 SUCCESS\n",
      "Total MapReduce CPU Time Spent: 23 seconds 230 msec\n",
      "OK\n",
      "javascript\t1\t5\t2771\t192\n",
      "java\t2\t2\t2033\t243\n",
      "android\t3\t52\t1809\t25\n",
      "php\t4\t3\t1673\t215\n",
      "python\t5\t11\t1585\t108\n",
      "c#\t6\t1\t1519\t423\n",
      "html\t7\t14\t1212\t84\n",
      "jquery\t8\t8\t1167\t141\n",
      "ios\t9\t186\t914\t7\n",
      "css\t10\t20\t801\t59\n",
      "Time taken: 221.63 seconds, Fetched: 10 row(s)\n"
     ]
    }
   ],
   "source": [
    "!hive -f assg2_result.hql"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "901_to_students.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
